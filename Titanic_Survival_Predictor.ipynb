{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4266c3c7",
   "metadata": {},
   "source": [
    "\n",
    "# Titanic Survival Predictor (Notebook)\n",
    "\n",
    "This notebook trains a **Titanic survival** classifier using a resilient data-loading pattern similar to your example:\n",
    "- Try multiple public sources (with/without headers)\n",
    "- Normalize column names to a standard schema\n",
    "- Save a local cached CSV under `data/titanic.csv` for reproducibility\n",
    "\n",
    "It then performs cleaning, feature engineering, modeling (Logistic Regression & Random Forest), evaluation, feature importance, and model export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "from pathlib import Path\n",
    "import io\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling & pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Saving model\n",
    "import joblib\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Versions →\", {\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d9647",
   "metadata": {},
   "source": [
    "## Data loading with multiple sources and header handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda73aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Two public sources with slightly different schemas.\n",
    "# (Kaggle originals require auth; these mirrors are open.)\n",
    "SOURCES = [\n",
    "    # Datasciencedojo version (has many columns incl. Name, Ticket, Cabin, Embarked)\n",
    "    \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\",\n",
    "    # Plotly version (columns slightly different; e.g., 'Siblings/Spouses Aboard')\n",
    "    \"https://raw.githubusercontent.com/plotly/datasets/master/titanic.csv\",\n",
    "]\n",
    "\n",
    "# We'll standardize to these columns when possible.\n",
    "COLUMNS = [\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "\n",
    "data_path = Path('data/titanic.csv')\n",
    "data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helper: unify schema across variants\n",
    "def normalize_titanic_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Work on a copy\n",
    "    df = df.copy()\n",
    "\n",
    "    # Common alternative column names\n",
    "    rename_map = {\n",
    "        'Siblings/Spouses Aboard': 'SibSp',\n",
    "        'Parents/Children Aboard': 'Parch',\n",
    "        'siblings/spouses aboard': 'SibSp',\n",
    "        'parents/children aboard': 'Parch',\n",
    "        'pclass': 'Pclass',\n",
    "        'sex': 'Sex',\n",
    "        'age': 'Age',\n",
    "        'sibsp': 'SibSp',\n",
    "        'parch': 'Parch',\n",
    "        'fare': 'Fare',\n",
    "        'embarked': 'Embarked',\n",
    "        'survived': 'Survived',\n",
    "    }\n",
    "\n",
    "    # Lowercase -> attempt rename, then titlecase back where applicable\n",
    "    lower_cols = {c: c.lower() for c in df.columns}\n",
    "    df.columns = [lower_cols[c] for c in df.columns]\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # Fix titlecase for known set\n",
    "    df.rename(columns={\n",
    "        'pclass': 'Pclass',\n",
    "        'sex': 'Sex',\n",
    "        'age': 'Age',\n",
    "        'sibsp': 'SibSp',\n",
    "        'parch': 'Parch',\n",
    "        'fare': 'Fare',\n",
    "        'embarked': 'Embarked',\n",
    "        'survived': 'Survived',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # If 'PassengerId' is present, we don't need it\n",
    "    drop_candidates = [\"PassengerId\", \"passengerid\", \"Name\", \"name\", \"Ticket\", \"ticket\", \"Cabin\", \"cabin\"]\n",
    "    for col in drop_candidates:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # If the Plotly version lacks Embarked, create it as NaN (will be imputed later)\n",
    "    import numpy as _np\n",
    "    if 'Embarked' not in df.columns:\n",
    "        df['Embarked'] = _np.nan\n",
    "\n",
    "    # Ensure columns exist; if some are missing, add as NaN\n",
    "    for col in COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = _np.nan\n",
    "\n",
    "    # Finally, keep only our standard set (order matters)\n",
    "    df = df[COLUMNS]\n",
    "    return df\n",
    "\n",
    "def try_download():\n",
    "    for url in SOURCES:\n",
    "        try:\n",
    "            print(f'Trying {url} ...')\n",
    "            with urlopen(url, timeout=20) as resp:\n",
    "                text = resp.read().decode('utf-8')\n",
    "            # Try to read as CSV directly\n",
    "            df_raw = pd.read_csv(io.StringIO(text))\n",
    "            # If it came without headers (unlikely for these sources), synthesize generic headers\n",
    "            if list(df_raw.columns) == list(range(df_raw.shape[1])):\n",
    "                # Make a best-effort guess — we will just assign plausible headers and normalize\n",
    "                guessed = df_raw\n",
    "                guessed.columns = [f\"col_{i}\" for i in range(df_raw.shape[1])]\n",
    "                df = normalize_titanic_columns(guessed)\n",
    "            else:\n",
    "                df = normalize_titanic_columns(df_raw)\n",
    "\n",
    "            # Save local copy\n",
    "            df.to_csv(data_path, index=False)\n",
    "            print('Downloaded and saved to', data_path.resolve())\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print('  Failed:', e)\n",
    "    return None\n",
    "\n",
    "# Load local or download\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print('Loaded local data from', data_path.resolve())\n",
    "else:\n",
    "    df = try_download()\n",
    "    if df is None:\n",
    "        raise RuntimeError(\n",
    "            \"Could not download dataset. Please place a file 'data/titanic.csv' locally \"\n",
    "            \"with columns: \" + \", \".join(COLUMNS)\n",
    "        )\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6028e",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.describe(include='all').T)\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6f32d",
   "metadata": {},
   "source": [
    "## Train/test split and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec03784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target and features\n",
    "target = \"Survived\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].astype(int)  # ensure binary ints 0/1\n",
    "\n",
    "# Simple train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_features = [\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]\n",
    "categorical_features = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Two candidate models\n",
    "log_reg = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=300, random_state=42, class_weight=None\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Cross-validate both\n",
    "for name, model in [(\"LogisticRegression\", log_reg), (\"RandomForest\", rf)]:\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "    print(f\"{name} ROC-AUC (CV): {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0f920",
   "metadata": {},
   "source": [
    "## Train final model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit both and pick the better on validation ROC-AUC quickly\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "def eval_model(pipe, label):\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    if y_proba is not None:\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"ROC-AUC: {auc:.3f}\")\n",
    "        RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "        plt.title(f\"ROC Curve — {label}\")\n",
    "        plt.show()\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Confusion Matrix — {label}\")\n",
    "    plt.show()\n",
    "\n",
    "eval_model(log_reg, \"Logistic Regression\")\n",
    "eval_model(rf, \"Random Forest\")\n",
    "\n",
    "# Choose best based on test ROC-AUC (fallback: accuracy if proba missing)\n",
    "def get_auc(pipe):\n",
    "    proba = pipe.predict_proba(X_test)[:,1]\n",
    "    return roc_auc_score(y_test, proba)\n",
    "\n",
    "auc_log = get_auc(log_reg)\n",
    "auc_rf  = get_auc(rf)\n",
    "\n",
    "best_model, best_name = (rf, \"RandomForest\") if auc_rf >= auc_log else (log_reg, \"LogisticRegression\")\n",
    "print(f\"\\nBest model selected: {best_name} (AUC: {max(auc_rf, auc_log):.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f624a",
   "metadata": {},
   "source": [
    "## Feature importance / coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature names after preprocessing\n",
    "preprocessor = best_model.named_steps[\"preprocess\"]\n",
    "\n",
    "num_feats = preprocessor.transformers_[0][2]\n",
    "cat_feats = list(preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"].get_feature_names_out(categorical_features))\n",
    "all_features = list(num_feats) + cat_feats\n",
    "\n",
    "if best_name == \"LogisticRegression\":\n",
    "    coefs = best_model.named_steps[\"clf\"].coef_[0]\n",
    "    imp = pd.Series(coefs, index=all_features).sort_values(key=np.abs, ascending=False)\n",
    "    imp.head(20).plot(kind=\"barh\")\n",
    "    plt.title(\"Top |coefficients| — Logistic Regression\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "else:\n",
    "    importances = best_model.named_steps[\"clf\"].feature_importances_\n",
    "    imp = pd.Series(importances, index=all_features).sort_values(ascending=True)\n",
    "    imp.tail(20).plot(kind=\"barh\")\n",
    "    plt.title(\"Top Feature Importances — Random Forest\")\n",
    "    plt.show()\n",
    "\n",
    "imp_df = imp.sort_values(ascending=False).reset_index()\n",
    "imp_df.columns = [\"feature\",\"importance\"]\n",
    "display(imp_df.head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c6e7b",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_path = models_dir / f\"titanic_{best_name.lower()}.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(\"Saved model to:\", model_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c7301",
   "metadata": {},
   "source": [
    "## Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example passenger(s): list of dicts\n",
    "example = pd.DataFrame([\n",
    "    {\"Pclass\": 3, \"Sex\": \"male\",   \"Age\": 22.0, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 7.25,  \"Embarked\": \"S\"},\n",
    "    {\"Pclass\": 1, \"Sex\": \"female\", \"Age\": 38.0, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 71.28, \"Embarked\": \"C\"},\n",
    "])\n",
    "\n",
    "loaded = joblib.load(model_path)\n",
    "pred_proba = loaded.predict_proba(example)[:,1]\n",
    "pred = loaded.predict(example)\n",
    "out = example.copy()\n",
    "out[\"Survival_Prob\"] = pred_proba\n",
    "out[\"Survival_Pred\"] = pred\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1718952",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24763a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, sklearn\n",
    "print({\n",
    "    \"python\": sys.version,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"scikit_learn\": sklearn.__version__,\n",
    "})\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
